{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Numpy Experiments\n\nWe provide a common use case with ``numpy`` and ``dman``.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview\n\nConsider the following simple code to compute least-squares estimates.\nWe would like to run a batch experiment on this estimator to evaluate its\nperformance for different sample sizes. While doing so we want to\nkeep track of our data and how it was generated.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport numpy.random as npr\n\n\ndef gather_data(\n    nb_samples: int, *, std: float = 0.1, theta=None, rg: npr.Generator = None\n):\n    if rg is None:\n        rg = npr.default_rng()\n    if theta is None:\n        theta = [0.5, 3]\n    x = rg.uniform(0, 1, size=nb_samples)\n    e = rg.standard_normal(size=nb_samples) * std\n    y = theta[0] * x + theta[1] + e\n    return (x, y)\n\n\ndef regressors(x: np.ndarray):\n    return np.vstack([x, np.ones(len(x))]).T\n\n\nx, y = gather_data(10)\nth = np.linalg.lstsq(regressors(x), y, rcond=None)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment configuration\n\nFirst we need to somehow represent an experiment configuration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import dman\nfrom typing import Sequence\n\n\n@dman.modelclass(name=\"model\", storable=True)\nclass Model:\n    \"\"\"Linear model.\n    Support storing in a file (storable=True)\n    \"\"\"\n\n    theta: Sequence[float] = (0.5, 3)\n    std: float = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we take a look at the serialization of ``Model`` we see that\nthe result could be significantly more compact.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from dman import tui\n\ntui.print_serializable(Model())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The current serialization has been automatically generated by ``dman``.\nInstead a custom serialization procedure can be specified.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import re\n\n\n@dman.modelclass(name=\"model\", storable=True)\nclass Model:\n    \"\"\"Linear model.\n    Support storing in a file (storable=True)\n    \"\"\"\n\n    theta: Sequence[float] = (0.5, 3)\n    std: float = 0.1\n\n    def __serialize__(self):\n        return f\"Model(theta={str(list(self.theta))}, std={self.std})\"\n\n    @classmethod\n    def __deserialize__(cls, ser):\n        pattern = r\"Model\\(theta=\\[(?P<theta>[0-9., ]+)\\], std=(?P<std>[0-9.]*)\\)\"\n        m = re.search(pattern, ser).groupdict()\n        theta, std = m[\"theta\"], m[\"std\"]\n        return cls([float(i) for i in theta.split(\",\")], float(std))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can then create a gallery of models as follows:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gallery = dman.mdict(store_by_key=True, store_subdir=False)\ngallery.update(\n    {\n        \"default\": Model(theta=(0.5, 3), std=0.1),\n        \"flat\": Model(theta=(0, 1.0), std=0.1),\n        \"steep\": Model(theta=(10.0, 0.0), std=0.1),\n        \"noisy\": Model(theta=(0.5, 3), std=5.0),\n    }\n)\n\ndman.save(\"__gallery\", gallery, generator=\"gallery\", cluster=False)\ntui.walk_directory(\n    dman.mount(key=\"\", generator=\"gallery\", cluster=False), show_content=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Models can then be loaded from the gallery as follows\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def model(key: str):\n    return dman.load(\"__gallery\", generator=\"gallery\", cluster=False)[key]\n\n\nprint(model(\"default\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that ``modelclass`` acts like a ``dataclass``, but supports some additional\nfield types. Some examples are given below.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We specify that the field should be serialized (not stored)\n# an alternative would be ``dman.field`` or ``dman.recordfield``\n# in which case the model would be stored in a separate file\n# from the configuration.\n_model_field = dman.serializefield(default_factory=Model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comparable arrays (``carray``)\nprovide some additional functionality when used in a ``modelclass``\nespecially useful in configuration classes. We specifically state that the\narray is of type integer and should  be comparable.\nWhen assigning an array to the class, it will be converted automatically.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from dman.numeric import carray\n@dman.modelclass(name=\"config\", storable=True, compact=True)\nclass Configuration:\n    \"\"\"Experiment Configuration.\"\"\"\n\n    model: Model = _model_field\n    nb_samples: carray[int] = dman.field(default_factory=lambda: np.logspace(1, 3, 20))\n    nb_repeats: int = 1000\n    seed: int = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note how we simply pass some logspace to ``nb_samples`` as default factory.\nThe input there will be converted to (numpy) integers automatically.\nAll types in ``dman.numeric`` -- that is ``sarray``, ``carray`` and ``barray``\ncan be typed similarly to how we do for ``carray`` here.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"type of nb_samples:\", type(Configuration().nb_samples[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also compare configurations (since we specified ``carray``)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\n    \"check for configs:\",\n    Configuration() == Configuration(nb_samples=np.logspace(1, 3, 20)),\n    Configuration() == Configuration(nb_samples=np.logspace(2, 3, 20)),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Executing experiments\nWe can now define the experiment behavior. We can do so as follows:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from dataclasses import asdict\n\n\ndef execute(model: Model, nb_samples: int, *, rg: npr.Generator = None):\n    x, y = gather_data(nb_samples, **asdict(model), rg=rg)\n    th, res, _, _ = np.linalg.lstsq(regressors(x), y, rcond=None)\n    return np.linalg.norm(th - model.theta, ord=2), res\n\n\n# Specify the location of the data using a recordfield.\n# The data will be stored in:\n#   ./data/<key>.<suffix>\n# for each (storable) key.\n_data_field = dman.recordfield(\n    default_factory=lambda: (dman.smdict(store_subdir=False, store_by_key=True)),\n    subdir=\"data\",\n    stem=\"__data\",\n    repr=False,\n)\n\n\nfrom dman.numeric import barray\n\n\n@dman.modelclass(storable=True, compact=True)\nclass Experiment:\n    \"\"\"Experiment result.\"\"\"\n\n    model: Model = dman.serializefield()\n    nb_samples: int\n    nb_repeats: int\n    data: dman.smdict = _data_field\n\n    @classmethod\n    def generate(cls, cfg: Configuration, idx: int, *, verbose: bool = True):\n        rg = npr.default_rng(cfg.seed)\n        res = cls(\n            model=cfg.model, nb_samples=cfg.nb_samples[idx], nb_repeats=cfg.nb_repeats\n        )\n        res.data.update(\n            {\n                \"error\": np.zeros((cfg.nb_repeats,)).view(barray),\n                \"residual\": np.zeros((cfg.nb_repeats)).view(barray),\n            }\n        )\n\n        _iter = range(cfg.nb_repeats)\n        if verbose:\n            _iter = tui.track(\n                _iter, total=cfg.nb_repeats, description=\"Executing experiment ...\"\n            )\n        for i in _iter:\n            res.data[\"error\"][i], res.data[\"residual\"][i] = execute(\n                cfg.model, cfg.nb_samples[idx], rg=rg\n            )\n        return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can run one experiment:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "exp = Experiment.generate(Configuration(nb_repeats=5), idx=0)\ndman.save(\"demo-modelclass\", exp)\ntui.walk_directory(dman.mount(\"demo-modelclass\"), show_content=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The creation of the data dictionary is somewhat verbose. Instead\nwe can again create a data modelclass\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@dman.modelclass(store_by_field=True, storable=True, compact=True)\nclass DataItem:\n    error: barray\n    residual: barray    \n\n\n@dman.modelclass(storable=True, compact=True)\nclass Experiment:\n    \"\"\"Experiment result.\"\"\"\n\n    model: Model = dman.serializefield()  # Store the model in experiment json.\n    nb_samples: int\n    nb_repeats: int\n    data: DataItem = dman.recordfield(stem='__data', subdir='data', default=None)\n\n    @classmethod\n    def generate(cls, cfg: Configuration, idx: int, *, verbose: bool = True):\n        rg = npr.default_rng(cfg.seed)\n        res = cls(\n            model=cfg.model, nb_samples=cfg.nb_samples[idx], nb_repeats=cfg.nb_repeats\n        )\n        res.data = DataItem(np.zeros((cfg.nb_repeats,)), np.zeros((cfg.nb_repeats)))\n        _iter = range(cfg.nb_repeats)\n        if verbose:\n            _iter = tui.track(\n                _iter, total=cfg.nb_repeats, description=\"Executing experiment ...\"\n            )\n        for i in _iter:\n            res.data.error[i], res.data.residual[i] = execute(\n                cfg.model, cfg.nb_samples[idx], rg=rg\n            )\n        return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No need to convert to ``barray``. We can again store the experiment:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "exp = Experiment.generate(Configuration(nb_repeats=5), idx=0)\ndman.save(\"demo\", exp)\ntui.walk_directory(dman.mount(\"demo\"), show_content=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To store multiple experiments we can use a ``mruns`` object.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "runs = dman.smruns(stem=\"experiment\", subdir=\"experiments\")\ncfg = Configuration(model=model(\"flat\"), nb_samples=[10, 100, 1000])\nfor i in tui.track(range(len(cfg.nb_samples)), total=len(cfg.nb_samples)):\n    runs.append(Experiment.generate(cfg, idx=i, verbose=False))\n\ndman.save(\n    \"experiment\", dman.mdict.from_dict({\"cfg\": cfg, \"experiments\": runs}, store_by_key=True)\n)\ntui.walk_directory(dman.mount(\"experiment\"), show_content=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-danger\"><h4>Warning</h4><p>It is always important to keep in mind how you defined your file hierarchy,\n      especially when dealing with modelclasses. For example an instance of\n      ``Experiment`` will always write the errors to ./data/error.npy. If\n      you try to serialize two instances to the same folder therefore, the data\n      will be overridden.</p></div>\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}